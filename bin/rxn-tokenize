#!/usr/bin/env python
# LICENSED INTERNAL CODE. PROPERTY OF IBM.
# IBM Research Zurich Licensed Internal Code
# (C) Copyright IBM Corp. 2020
# ALL RIGHTS RESERVED
import os
import sys
from typing import Tuple

import click
import pandas as pd

import rxn_reaction_preprocessing as rrp


@click.command()
@click.argument('input_output_pairs', type=click.Path(), nargs=-1, required=True)
def cli(input_output_pairs: Tuple[str]) -> None:
    """The entry point for this cli script.

    Args:
        input_output_pairs (Tuple[str]):  Paths to the input and output files in the form <input_a> <output_a> <input_b> <output_b> [...].
    """

    if len(input_output_pairs) % 2 != 0:
        print()
        raise SystemExit(
            f'Files must be supplied as input output pairs in the form <input_a> <output_a> <input_b> <output_b> [...]:\n{input}'
        )

    # Tokenize the reactions
    tokenizer = rrp.SmilesTokenizer()

    for input, output in zip(input_output_pairs[::2], input_output_pairs[1::2]):
        df = pd.read_csv(input)

        if 'rxn' not in df.columns:
            raise SystemExit(f'The following file does not contain an rxn column:\n{input}')

        df['rxn_precursors'] = df.rxn.str.split('>>').str[0]
        df['rxn_products'] = df.rxn.str.split('>>').str[1]

        df.rxn_precursors = df.rxn_precursors.apply(tokenizer.tokenize)
        df.rxn_products = df.rxn_products.apply(tokenizer.tokenize)

        df[['rxn_precursors']].to_csv(f'{output}.precursors_tokens', header=False, index=False)
        df[['rxn_products']].to_csv(f'{output}.products_tokens', header=False, index=False)


if __name__ == '__main__':
    cli()
